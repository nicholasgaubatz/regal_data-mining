{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atzzCIBpyU2N"
   },
   "source": [
    "# Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gbQ00kFAKaqk"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import sparse\n",
    "from aligning import *\n",
    "from extract import *\n",
    "from representation import *\n",
    "from configuration import RepMethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ly6BjJF_yF2q"
   },
   "source": [
    "# Read in the graphs for the first analysis\n",
    "\n",
    "We are comparing the database of Deezer users in Romania and Hungary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oRzjMaq6OwMX"
   },
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"RO_edges.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VVootXMIK0Ou"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"HU_edges.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R33j4WaOymd7"
   },
   "source": [
    "# Extract the features\n",
    "Step 1 of regal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "c6A1skZJK99L"
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df, source='node_1', target='node_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "34w-KIWfP0Qn"
   },
   "outputs": [],
   "source": [
    "G2= nx.from_pandas_edgelist(df2, source='node_1', target='node_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2H3IM0kHLBIV"
   },
   "outputs": [],
   "source": [
    "adj_matrix=nx.adjacency_matrix(G)\n",
    "adj_matrix2 = nx.adjacency_matrix(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "nH0YF3SBLN_O"
   },
   "outputs": [],
   "source": [
    "adj_matrix_combined = sparse.block_diag([adj_matrix, adj_matrix2])\n",
    "\n",
    "# Initialize the graph objects\n",
    "graph1 = Graph(adj_matrix)\n",
    "graph2 = Graph(adj_matrix2)\n",
    "graph3 = Graph(adj_matrix_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDPtlR52yxYJ"
   },
   "source": [
    "I commented out the node identities 1 and 2 to lower runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MGioP1XLSN8",
    "outputId": "15a44553-5e26-451c-d190-1963d05ae460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node Identities for Graph 3:\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "K = 2  # Maximum hop distance\n",
    "delta = 0.5  # Discount factor\n",
    "\n",
    "# Extract node identities for both graphs\n",
    "#node_identities_1 = extract_node_identity(graph1, K, delta)\n",
    "#node_identities_2 = extract_node_identity(graph2, K, delta)\n",
    "node_identities_3 = extract_node_identity(graph3, K, delta)\n",
    "\n",
    "#print(\"Node Identities for Graph 1:\\n\", node_identities_1)\n",
    "#print(\"\\nNode Identities for Graph 2:\\n\", node_identities_2)\n",
    "print(\"\\nNode Identities for Graph 3:\\n\", node_identities_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gosLAuGTy5Zc"
   },
   "source": [
    "# Get the representations of the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1IsJ_egRkY0",
    "outputId": "c900c381-dcba-43bd-b93e-03d7cb68df0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of landmark nodes: None\n"
     ]
    }
   ],
   "source": [
    "rep_method = RepMethod(max_layer=2)\n",
    "print('Number of landmark nodes:', rep_method.p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxBUGPRCTeeF",
    "outputId": "5629cf3d-9cc1-42ea-ef73-f0e3ca256c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "get_number_of_landmarks(graph3, rep_method)\n",
    "print(rep_method.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBtBBrjMRlxL",
    "outputId": "66499532-8eb0-4d43-8262-28ec22339c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17990 33676 10263 75971 16864 71567 80912 74787 26535  9860 64507 56182\n",
      " 21460 82676 76328 49099 74657 21076 56290 54192 79016 76013 51012  5756\n",
      "  3301 41486 29967  4526 64809 42670 61562 64449 36613  5550 69753 30450\n",
      " 88673 48556 40178 70982 56012 28734 84442  5925 37365  8659 13748  9150\n",
      " 48767 64683 22526 63239 23846 87394 41996 16307 82443 16970 61690 54469\n",
      " 20124 68340  1711 77421  6501 82977 63394  6033 67205 46640  7541 19992\n",
      " 39236  1535 25675 81272 75403 57533 67902 73197 37312 15017  9559 84980\n",
      " 28052 66566 66618 55409 32698 36858 20626 39013 58546 14966  3899 76940\n",
      " 43083 81741 42454 40077 34883 48598 17289 61234 21086 79031  4378 15285\n",
      " 75528 41447 81664  3182 87127 23271 58484 53590 56326 25047 75198 33840\n",
      "  7069 55650 45183 87218 44781 61128 82896 56373 66711 19319 35628 43750\n",
      " 12443  8688 46037 42740 37335 66433 14726 75057 10000 13087  4147 31157\n",
      " 73247 48950 66530  8349 74515 87083 67239 49233  1410 27808 87496 70640\n",
      " 46390 84566 67198  6908 25491 73335 85251 40063]\n"
     ]
    }
   ],
   "source": [
    "landmarks = get_random_landmarks(graph3, rep_method)\n",
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYkCrcICRtxm",
    "outputId": "a2348f68-5b96-4380-e117-870a07c8e41e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\n",
      "[[1.29958143e-024 7.28129018e-033 1.60381089e-028 ... 4.07955867e-041\n",
      "  2.17052201e-029 4.76403211e-101]\n",
      " [1.87952882e-012 1.71390843e-015 2.31952283e-016 ... 4.65888615e-015\n",
      "  9.35762297e-014 1.92194773e-098]\n",
      " [2.78946809e-010 4.65888615e-015 2.54366565e-013 ... 2.78946809e-010\n",
      "  7.58256043e-010 3.38030668e-123]\n",
      " ...\n",
      " [1.38879439e-011 9.35762297e-014 2.31952283e-016 ... 6.73794700e-003\n",
      "  6.14421235e-006 3.90365393e-140]\n",
      " [2.54366565e-013 9.35762297e-014 3.13913279e-017 ... 3.67879441e-001\n",
      "  8.31528719e-007 7.14979157e-142]\n",
      " [3.77513454e-011 4.65888615e-015 1.15482242e-017 ... 3.35462628e-004\n",
      "  3.05902321e-007 7.84069851e-139]]\n"
     ]
    }
   ],
   "source": [
    "C = compute_C_matrix(node_identities_3, landmarks)\n",
    "(f'Shape of C: {len(C)} x {len(C[0])}')\n",
    "print('C:')\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kuhur3tcRDp0",
    "outputId": "21477e01-ff67-4f59-ab6e-066ddd840a3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations of nodes from first graph:\n",
      "[[-9.08563624e-13 -9.62075620e-13  2.93953424e-11 ...  5.38881856e-13\n",
      "  -1.87044235e-26  9.46306569e-26]\n",
      " [ 5.57212829e-06  3.06657581e-06 -1.22482651e-05 ...  4.81005433e-06\n",
      "  -1.17684302e-24 -2.51675083e-25]\n",
      " [-1.00128301e-03 -2.50086135e-05  5.76052206e-04 ...  1.20824276e-03\n",
      "  -2.76944465e-24  3.66126019e-24]\n",
      " ...\n",
      " [-1.44905463e-01  8.51030397e-02 -9.94035323e-03 ...  8.96406684e-01\n",
      "   1.95686270e-24  4.24678479e-24]\n",
      " [-1.60667698e-02 -2.62665133e-04  1.24732031e-02 ...  1.40475190e-01\n",
      "   2.08523174e-25  3.89093920e-26]\n",
      " [ 7.63574115e-02 -6.06198858e-01 -2.17149988e-01 ...  4.27968764e-01\n",
      "   7.26524174e-25  2.23192706e-24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nps0027\\Downloads\\representation.py:74: RuntimeWarning: divide by zero encountered in divide\n",
      "  Y_twiddle = Y_twiddle / np.linalg.norm(Y_twiddle, axis=1).reshape(Y_twiddle.shape[0], 1) # Normalization of rows\n",
      "C:\\Users\\nps0027\\Downloads\\representation.py:74: RuntimeWarning: invalid value encountered in divide\n",
      "  Y_twiddle = Y_twiddle / np.linalg.norm(Y_twiddle, axis=1).reshape(Y_twiddle.shape[0], 1) # Normalization of rows\n"
     ]
    }
   ],
   "source": [
    "representations_1, representations_2 = compute_representation(C, landmarks, adj_matrix.shape[0])\n",
    "print('Representations of nodes from first graph:')\n",
    "print(representations_1)\n",
    "representations_1= np.nan_to_num(representations_1, nan=0)\n",
    "representations_2= np.nan_to_num(representations_2, nan=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm4Grv96zBMU"
   },
   "source": [
    "# Calculate Similarity Matrix\n",
    "Similarity for the alignment of Graph 1 and 2, showing the 3 most similar nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZrUDiMMUwqF",
    "outputId": "0c750ffa-d1a7-442c-9918-298bb3f7c2ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8306)\t0.9543844291838592\n",
      "  (0, 11472)\t0.9523321303424711\n",
      "  (0, 2034)\t0.951952291332164\n",
      "  (1, 29719)\t0.9453015440336867\n",
      "  (1, 20105)\t0.9452474129358718\n",
      "  (1, 8111)\t0.9452109238476236\n",
      "  (2, 37508)\t0.9692400066541615\n",
      "  (2, 1625)\t0.9666039605194034\n",
      "  (2, 9306)\t0.966576561917957\n",
      "  (3, 22278)\t0.9913392204469409\n",
      "  (3, 12790)\t0.9912850712906756\n",
      "  (3, 17956)\t0.9898027553553443\n",
      "  (4, 7690)\t0.9530120863548616\n",
      "  (4, 11691)\t0.9506533988332544\n",
      "  (4, 18041)\t0.9481328444958254\n",
      "  (5, 2575)\t0.9871560970840966\n",
      "  (5, 17859)\t0.9865347527722774\n",
      "  (5, 621)\t0.9855335742682437\n",
      "  (6, 322)\t0.9904727009092665\n",
      "  (6, 23767)\t0.9806142349103905\n",
      "  (6, 31637)\t0.956901154954738\n",
      "  (7, 11857)\t0.9839128726695014\n",
      "  (7, 24498)\t0.9555623153458805\n",
      "  (7, 28554)\t0.8948736204783071\n",
      "  (8, 496)\t0.999980871172973\n",
      "  :\t:\n",
      "  (47529, 1407)\t1.0\n",
      "  (47530, 11635)\t1.0\n",
      "  (47530, 15437)\t1.0\n",
      "  (47530, 20948)\t1.0\n",
      "  (47531, 13949)\t0.9044208564113484\n",
      "  (47531, 4196)\t0.9044208564113484\n",
      "  (47531, 710)\t0.9044208564113484\n",
      "  (47532, 21550)\t1.0\n",
      "  (47532, 36077)\t1.0\n",
      "  (47532, 38767)\t1.0\n",
      "  (47533, 2156)\t1.0\n",
      "  (47533, 3949)\t1.0\n",
      "  (47533, 1935)\t1.0\n",
      "  (47534, 1758)\t1.0\n",
      "  (47534, 1734)\t1.0\n",
      "  (47534, 268)\t1.0\n",
      "  (47535, 2156)\t1.0\n",
      "  (47535, 3949)\t1.0\n",
      "  (47535, 1935)\t1.0\n",
      "  (47536, 12096)\t0.9977422161245784\n",
      "  (47536, 38200)\t0.9977422161245784\n",
      "  (47536, 12100)\t0.9977422161245784\n",
      "  (47537, 22739)\t1.0\n",
      "  (47537, 22360)\t1.0\n",
      "  (47537, 5818)\t1.0\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = get_similarity_matrix(representations_1, representations_2, 3)\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis\n",
    "## Helper Functions\n",
    "Function to generate a permutation of the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CBZT2n97eRHP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "def generate_noisy_adjacency(A, ps=0.1, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a permuted and noisy adjacency matrix A'.\n",
    "\n",
    "    Parameters:\n",
    "    - A (np.ndarray): Original adjacency matrix (square and symmetric for undirected networks).\n",
    "    - ps (float): Probability of removing an edge as noise (0 ≤ ps ≤ 1).\n",
    "    - seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - A_prime (np.ndarray): Noisy permuted adjacency matrix.\n",
    "    - P (np.ndarray): Permutation matrix used for reordering.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Step 1: Create a random permutation matrix P\n",
    "    perm = np.random.permutation(n)\n",
    "    P = np.eye(n)[perm]\n",
    "    # Step 2: Compute the permuted adjacency matrix A' = PAP^T\n",
    "    A_prime = P @ A @ P.T\n",
    "\n",
    "    # Step 3: Add structural noise by removing edges with probability ps\n",
    "    G = nx.from_numpy_array(A_prime)  # Convert to a NetworkX graph\n",
    "    edges = list(G.edges)  # Get the initial list of edges\n",
    "    num_edges_to_remove = int(ps * len(edges))\n",
    "\n",
    "    # Randomly remove edges, ensuring the graph stays connected\n",
    "    removed_edges = 0\n",
    "    while removed_edges < num_edges_to_remove:\n",
    "        # Refresh the list of edges to avoid KeyError\n",
    "        edges = list(G.edges)\n",
    "        \n",
    "        if len(edges) == 0:\n",
    "            break  # Stop if no more edges are left to remove\n",
    "        \n",
    "        edge_to_remove = edges[np.random.randint(len(edges))]\n",
    "        \n",
    "        # Remove the edge\n",
    "        G.remove_edge(*edge_to_remove)\n",
    "        \n",
    "        # Ensure the graph is still connected after removing the edge\n",
    "        if nx.is_connected(G):\n",
    "            removed_edges += 1\n",
    "        else:\n",
    "            G.add_edge(*edge_to_remove)  # Restore edge if disconnection occurs\n",
    "\n",
    "    # Convert back to adjacency matrix\n",
    "    A_prime = nx.to_numpy_array(G, dtype=int)\n",
    "\n",
    "    return A_prime, P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the similarity matrix to a permutation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def similarity_to_permutation(similarity_matrix):\n",
    "    \"\"\"\n",
    "    Convert the similarity matrix (sparse format) into a permutation matrix in sparse format.\n",
    "    \n",
    "    Args:\n",
    "    similarity_matrix: A sparse matrix of similarity scores, in COO format.\n",
    "    \n",
    "    Returns:\n",
    "    A sparse permutation matrix (COO format).\n",
    "    \"\"\"\n",
    "    # Get the number of rows and columns\n",
    "    n_rows, n_cols = similarity_matrix.shape\n",
    "    \n",
    "    # Lists to store the row, column indices, and values for the permutation matrix\n",
    "    perm_rows = []\n",
    "    perm_cols = []\n",
    "    perm_data = []\n",
    "    \n",
    "    # Iterate through each row and find the index of the maximum similarity value\n",
    "    for i in range(n_rows):\n",
    "        # Get the row's non-zero entries (stored as (index, value) pairs)\n",
    "        row_data = similarity_matrix.getrow(i)  # Sparse row\n",
    "        \n",
    "        # Find the index of the maximum similarity score for the current row\n",
    "        if row_data.nnz > 0:  # Check if the row is not empty\n",
    "            best_match_idx = row_data.argmax()  # Find index of the max value in sparse row\n",
    "            perm_rows.append(i)\n",
    "            perm_cols.append(best_match_idx)\n",
    "            perm_data.append(1)  # This is a permutation matrix, so value is always 1\n",
    "    \n",
    "    # Create a sparse matrix in COO format from the row, column indices and data\n",
    "    permutation_matrix_sparse = coo_matrix((perm_data, (perm_rows, perm_cols)), shape=(n_rows, n_cols))\n",
    "    \n",
    "    return permutation_matrix_sparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def evaluate_alignment(P, P_hat):\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of the recovered alignment.\n",
    " \n",
    "    Parameters:\n",
    "    - P (np.ndarray): Ground-truth permutation matrix.\n",
    "    - P_hat (np.ndarray): Recovered permutation matrix.\n",
    " \n",
    "    Returns:\n",
    "    - accuracy (float): Fraction of correctly aligned nodes.\n",
    "    - hamming_distance (int): Number of differing entries between P and P_hat.\n",
    "    \"\"\"\n",
    "    n = P.shape[0]\n",
    "    print(n)\n",
    "    # Compute the permutations (row indices of the 1's)\n",
    "    correct_permutation = np.argmax(P, axis=1)\n",
    "    predicted_permutation = np.argmax(P_hat, axis=1)\n",
    "    # Accuracy as fraction of correct permutations\n",
    "    correct_matches = np.sum(correct_permutation == predicted_permutation)\n",
    "    print(correct_matches)\n",
    "    accuracy = correct_matches / n\n",
    " \n",
    "    # Hamming distance: number of differing entries between P and P_hat\n",
    "    hamming_distance = np.sum(P != P_hat)/(n*P.shape[1])\n",
    " \n",
    "    return accuracy, hamming_distance\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to evaluate the alignment qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n",
      "2\n",
      "309\n",
      "1\n",
      "202\n",
      "0\n",
      "147\n",
      "1\n",
      "392\n",
      "1\n",
      "473\n",
      "2\n",
      "482\n",
      "1\n",
      "387\n",
      "1\n",
      "167\n",
      "3\n",
      "497\n",
      "1\n",
      "318\n",
      "1\n",
      "304\n",
      "1\n",
      "404\n",
      "0\n",
      "424\n",
      "0\n",
      "182\n",
      "4\n",
      "376\n",
      "0\n",
      "272\n",
      "0\n",
      "182\n",
      "2\n",
      "476\n",
      "0\n",
      "206\n",
      "1\n",
      "314\n",
      "1\n",
      "441\n",
      "1\n",
      "395\n",
      "1\n",
      "163\n",
      "1\n",
      "100\n",
      "1\n",
      "151\n",
      "2\n",
      "115\n",
      "1\n",
      "342\n",
      "2\n",
      "210\n",
      "2\n",
      "269\n",
      "1\n",
      "165\n",
      "0\n",
      "344\n",
      "1\n",
      "118\n",
      "1\n",
      "236\n",
      "1\n",
      "134\n",
      "1\n",
      "333\n",
      "0\n",
      "375\n",
      "0\n",
      "106\n",
      "3\n",
      "446\n",
      "1\n",
      "189\n",
      "1\n",
      "384\n",
      "1\n",
      "205\n",
      "0\n",
      "214\n",
      "1\n",
      "236\n",
      "0\n",
      "401\n",
      "0\n",
      "497\n",
      "2\n",
      "426\n",
      "0\n",
      "241\n",
      "1\n",
      "301\n",
      "2\n",
      "140\n",
      "3\n",
      "398\n",
      "4\n",
      "257\n",
      "0\n",
      "223\n",
      "3\n",
      "113\n",
      "2\n",
      "470\n",
      "1\n",
      "328\n",
      "0\n",
      "456\n",
      "0\n",
      "298\n",
      "4\n",
      "247\n",
      "2\n",
      "227\n",
      "0\n",
      "233\n",
      "0\n",
      "490\n",
      "1\n",
      "295\n",
      "0\n",
      "396\n",
      "0\n",
      "333\n",
      "0\n",
      "231\n",
      "0\n",
      "454\n",
      "0\n",
      "238\n",
      "0\n",
      "413\n",
      "0\n",
      "254\n",
      "2\n",
      "468\n",
      "1\n",
      "411\n",
      "1\n",
      "382\n",
      "0\n",
      "247\n",
      "0\n",
      "377\n",
      "1\n",
      "241\n",
      "1\n",
      "159\n",
      "1\n",
      "380\n",
      "3\n",
      "274\n",
      "2\n",
      "411\n",
      "1\n",
      "130\n",
      "1\n",
      "478\n",
      "0\n",
      "337\n",
      "0\n",
      "431\n",
      "0\n",
      "121\n",
      "3\n",
      "253\n",
      "2\n",
      "459\n",
      "1\n",
      "232\n",
      "0\n",
      "428\n",
      "0\n",
      "339\n",
      "2\n",
      "128\n",
      "1\n",
      "425\n",
      "0\n",
      "223\n",
      "1\n",
      "400\n",
      "3\n",
      "217\n",
      "1\n",
      "137\n",
      "1\n",
      "240\n",
      "1\n",
      "287\n",
      "1\n",
      "129\n",
      "1\n",
      "329\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "collected_accuracies = [0 for _ in range(100)]\n",
    "collected_hamming = [0 for _ in range(100)]\n",
    "K = 2  # Maximum hop distance\n",
    "delta = 0.5  # Discount factor\n",
    "for i in range(100): \n",
    "   \n",
    "    # Create a 100x100 matrix with random 0s and 1s\n",
    "    n = np.random.randint(100,501)\n",
    "    matrix = np.random.randint(2, size=(n, n))\n",
    "    A_hat, P_ground = generate_noisy_adjacency(matrix)\n",
    "    matrix = sparse.csr_matrix(matrix)\n",
    "    A_hat_t=  sparse.csr_matrix(A_hat)\n",
    "    P_hat = sparse.csr_matrix(P_ground)\n",
    "    adj_matrix_combined = sparse.block_diag([matrix, A_hat_t])\n",
    "    graph = Graph(adj_matrix_combined)\n",
    "    node_identities = extract_node_identity(graph, K, delta)\n",
    "    rep_method = RepMethod(max_layer=2)\n",
    "    get_number_of_landmarks(graph, rep_method)\n",
    "    landmarks = get_random_landmarks(graph, rep_method)\n",
    "    C = compute_C_matrix(node_identities, landmarks)\n",
    "    representations_1, representations_2 = compute_representation(C, landmarks, A_hat_t.shape[0])\n",
    "    representations_1= np.nan_to_num(representations_1, nan=0)\n",
    "    representations_2= np.nan_to_num(representations_2, nan=0)\n",
    "    similarity_matrix = get_similarity_matrix(representations_1, representations_2, 3)\n",
    "    P_align = similarity_to_permutation(similarity_matrix)\n",
    "    accuracy, hamming_distance = evaluate_alignment(P_align, P_hat )\n",
    "    collected_accuracies[i]=accuracy\n",
    "    collected_hamming[i]=hamming_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0046582366763398666"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(collected_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008001182834277996"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(collected_hamming)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
