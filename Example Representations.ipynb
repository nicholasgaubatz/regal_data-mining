{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example that computes the representation, as in step 2 of the xNetMF algorithm given on pages 4 and 5 of the paper.\n",
    "\n",
    "To run this notebook, ensure that config.py and xnetmf.py are in the same folder as this file. We probably shouldn't put them on GitHub, since we don't want to use any of their code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from config import * # Defines Graph and RepMethod classes that we use in step 1 placeholder\n",
    "from xnetmf import get_features # Computes the feature matrix in the step 1 placeholder\n",
    "\n",
    "from representation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Node identity extraction (placeholder)\n",
    "\n",
    "We compute the feature matrix using the paper's authors' source code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run only this block for two $1000 \\times 1000$ adjacency matrices. Run only the next block for a specific small example found in figure 2 of the paper. Run only the third block for a sanity check on two isomorphic graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'np.random.seed(1)\\n\\nA = sparse.csr_matrix( np.random.randint(2,size=(1000,1000)) )\\nB = sparse.csr_matrix( np.random.randint(2,size=(1000,1000)) )\\ncomb = sparse.block_diag([A, B])\\n\\ngraph = Graph(adj = comb.tocsr())\\nrep_method = RepMethod(max_layer = 2)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"np.random.seed(1)\n",
    "\n",
    "A = sparse.csr_matrix( np.random.randint(2,size=(1000,1000)) )\n",
    "B = sparse.csr_matrix( np.random.randint(2,size=(1000,1000)) )\n",
    "comb = sparse.block_diag([A, B])\n",
    "\n",
    "graph = Graph(adj = comb.tocsr())\n",
    "rep_method = RepMethod(max_layer = 2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'np.random.seed(1)\\n\\nA = sparse.csr_matrix(np.array([[0., 1., 1., 1., 0.],\\n                                [1., 0., 0., 0., 0.],\\n                                [1., 0., 0., 0., 0.],\\n                                [1., 0., 0., 0., 1.],\\n                                [0., 0., 0., 1., 0.]]))\\n\\nB = sparse.csr_matrix(np.array([[0., 1., 0., 0., 0., 0.],\\n                                [1., 0., 0., 1., 0., 0.],\\n                                [0., 0., 0., 1., 1., 0.],\\n                                [0., 1., 1., 0., 1., 1.],\\n                                [0., 0., 1., 1., 0., 0.],\\n                                [0., 0., 0., 1., 0., 0.]]))\\ncomb = sparse.block_diag([A, B])\\n\\ngraph = Graph(adj = comb.tocsr())\\nrep_method = RepMethod(max_layer=2)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"np.random.seed(1)\n",
    "\n",
    "A = sparse.csr_matrix(np.array([[0., 1., 1., 1., 0.],\n",
    "                                [1., 0., 0., 0., 0.],\n",
    "                                [1., 0., 0., 0., 0.],\n",
    "                                [1., 0., 0., 0., 1.],\n",
    "                                [0., 0., 0., 1., 0.]]))\n",
    "\n",
    "B = sparse.csr_matrix(np.array([[0., 1., 0., 0., 0., 0.],\n",
    "                                [1., 0., 0., 1., 0., 0.],\n",
    "                                [0., 0., 0., 1., 1., 0.],\n",
    "                                [0., 1., 1., 0., 1., 1.],\n",
    "                                [0., 0., 1., 1., 0., 0.],\n",
    "                                [0., 0., 0., 1., 0., 0.]]))\n",
    "comb = sparse.block_diag([A, B])\n",
    "\n",
    "graph = Graph(adj = comb.tocsr())\n",
    "rep_method = RepMethod(max_layer=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Same graph on 5 nodes as in the paper example.\n",
    "A = sparse.csr_matrix(np.array([[0., 1., 1., 1., 0.],\n",
    "                                [1., 0., 0., 0., 0.],\n",
    "                                [1., 0., 0., 0., 0.],\n",
    "                                [1., 0., 0., 0., 1.],\n",
    "                                [0., 0., 0., 1., 0.]]))\n",
    "\n",
    "# Permutation matrix. We can multiply perm*A*perm^T to get a new matrix whose nodes are permuted.\n",
    "perm = np.array([[0., 0., 0., 0., 1.],\n",
    "                 [0., 0., 0., 1., 0.],\n",
    "                 [0., 0., 1., 0., 0.],\n",
    "                 [0., 1., 0., 0., 0.],\n",
    "                 [1., 0., 0., 0., 0.]])\n",
    "# Isomorphism of first graph. Node correspondences are 0 -> 4, 1 -> 3, 2 -> 2, 3 -> 1, 4 -> 0. \n",
    "# Note that structurally, nodes 1 and 2 in the first graph and nodes 2 and 3 in the second graph are each identical. This shows up in the \n",
    "# result at the end of the notebook, where similarities are all 1.0 for each of them.\n",
    "B = sparse.csr_matrix(perm @ A @ perm.T)\n",
    "comb = sparse.block_diag([A, B])\n",
    "\n",
    "graph = Graph(adj = comb.tocsr())\n",
    "rep_method = RepMethod(max_layer=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature matrix, as computed in their source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max degree:  3\n",
      "got k hop neighbors in time:  0.0017342567443847656\n",
      "got degree sequences in time:  0.00011205673217773438\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = get_features(graph, rep_method, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.21 0.1  1.  ]\n",
      " [0.   1.01 0.01 0.1 ]\n",
      " [0.   1.01 0.01 0.1 ]\n",
      " [0.   0.12 1.   0.1 ]\n",
      " [0.   1.   0.1  0.01]\n",
      " [0.   1.   0.1  0.01]\n",
      " [0.   0.12 1.   0.1 ]\n",
      " [0.   1.01 0.01 0.1 ]\n",
      " [0.   1.01 0.01 0.1 ]\n",
      " [0.   0.21 0.1  1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Efficient similarity-based representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See representation.py for the custom code (based on the source code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compute the number of landmark nodes. Recall: this is, by default, the minimum of $p$ and $10\\log_{2}(n)$, where $n$ is the total number of nodes of the two graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of landmark nodes: None\n"
     ]
    }
   ],
   "source": [
    "print('Number of landmark nodes:', rep_method.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of landmark nodes: 10\n"
     ]
    }
   ],
   "source": [
    "get_number_of_landmarks(graph, rep_method)\n",
    "print('Number of landmark nodes:', rep_method.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the landmark nodes, which are chosen randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 9 6 4 0 3 1 7 8 5]\n"
     ]
    }
   ],
   "source": [
    "landmarks = get_random_landmarks(graph, rep_method)\n",
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity matrix between all $n$ nodes and all $p$ landmark nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of C: 10 x 10\n",
      "C:\n",
      "[[0.23267794 1.         0.19630219 0.20105033 1.         0.19630219\n",
      "  0.23267794 0.23267794 0.23267794 0.20105033]\n",
      " [1.         0.23267794 0.16995867 0.98383213 0.23267794 0.16995867\n",
      "  1.         1.         1.         0.98383213]\n",
      " [1.         0.23267794 0.16995867 0.98383213 0.23267794 0.16995867\n",
      "  1.         1.         1.         0.98383213]\n",
      " [0.16995867 0.19630219 1.         0.20341643 0.19630219 1.\n",
      "  0.16995867 0.16995867 0.16995867 0.20341643]\n",
      " [0.98383213 0.20105033 0.20341643 1.         0.20105033 0.20341643\n",
      "  0.98383213 0.98383213 0.98383213 1.        ]\n",
      " [0.98383213 0.20105033 0.20341643 1.         0.20105033 0.20341643\n",
      "  0.98383213 0.98383213 0.98383213 1.        ]\n",
      " [0.16995867 0.19630219 1.         0.20341643 0.19630219 1.\n",
      "  0.16995867 0.16995867 0.16995867 0.20341643]\n",
      " [1.         0.23267794 0.16995867 0.98383213 0.23267794 0.16995867\n",
      "  1.         1.         1.         0.98383213]\n",
      " [1.         0.23267794 0.16995867 0.98383213 0.23267794 0.16995867\n",
      "  1.         1.         1.         0.98383213]\n",
      " [0.23267794 1.         0.19630219 0.20105033 1.         0.19630219\n",
      "  0.23267794 0.23267794 0.23267794 0.20105033]]\n"
     ]
    }
   ],
   "source": [
    "C = compute_C_matrix(feature_matrix, landmarks)\n",
    "print(f'Shape of C: {len(C)} x {len(C[0])}')\n",
    "print('C:')\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, compute representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representations of nodes from first graph:\n",
      "[[ 4.56900521e-03 -6.58431416e-01  6.72364922e-01  3.38190192e-01\n",
      "  -1.71596070e-22 -4.73234254e-23 -1.03594553e-23 -9.63980388e-25\n",
      "   5.59299141e-34  3.23043692e-42]\n",
      " [-5.71310364e-02 -5.55393667e-04 -1.50521002e-01  9.86954489e-01\n",
      "  -5.41432549e-22 -1.79830815e-22 -1.52003362e-23 -1.26458943e-26\n",
      "  -1.26549410e-33 -4.48315658e-42]\n",
      " [-5.71310364e-02 -5.55393667e-04 -1.50521002e-01  9.86954489e-01\n",
      "  -5.41432549e-22 -1.79830815e-22 -1.52003362e-23 -1.26458943e-26\n",
      "  -1.26549410e-33 -4.48315658e-42]\n",
      " [-4.91875859e-03  6.06340953e-01  7.42187944e-01  2.85453168e-01\n",
      "  -1.36061535e-22 -4.56868336e-23 -5.48550594e-24  6.91417463e-25\n",
      "  -5.98226566e-34  3.68665225e-42]\n",
      " [ 1.14762456e-01  5.16489551e-02 -1.44822949e-01  9.81421560e-01\n",
      "  -5.42659225e-22 -1.79555798e-22 -1.50436178e-23 -1.30315414e-25\n",
      "  -1.25827277e-33  1.99914958e-42]]\n"
     ]
    }
   ],
   "source": [
    "representations_1, representations_2 = compute_representation(C, landmarks, A.shape[0])\n",
    "print('Representations of nodes from first graph:')\n",
    "print(representations_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Fast node representation alignment\n",
    "\n",
    "Now, we can plug this into step 3, as found in aligning.py and Example Alignments.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aligning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 20 stored elements and shape (5, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 4)\t1.0\n",
      "  (0, 2)\t0.2897295037335605\n",
      "  (0, 3)\t0.2897295037335605\n",
      "  (0, 0)\t0.2824989537646846\n",
      "  (1, 2)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (1, 0)\t0.8354193765345959\n",
      "  (1, 4)\t0.2897295037335605\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (2, 0)\t0.8354193765345959\n",
      "  (2, 4)\t0.2897295037335605\n",
      "  (3, 1)\t1.0\n",
      "  (3, 0)\t0.28302862283104374\n",
      "  (3, 4)\t0.2814413880972581\n",
      "  (3, 2)\t0.27570000246613857\n",
      "  (4, 0)\t1.0\n",
      "  (4, 2)\t0.8354193765345959\n",
      "  (4, 3)\t0.8354193765345959\n",
      "  (4, 1)\t0.28302862283104374\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = get_similarity_matrix(representations_1, representations_2, 4)\n",
    "print(similarity_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
